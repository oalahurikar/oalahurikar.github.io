---
layout: mermaid-post
tags:
  - ai
  - project
---

This is project I did onğŸš¦Â **Traffic Sign Classifier Using Deep Learning (TensorFlow)**
if you are interested in code its here [Project github repo](https://github.com/oalahurikar/Self-Driving/tree/master/Term1/2.%20Traffic%20Sign%20Classifier#readme).


## ğŸ“Â **Project Overview**

The goal of this project was toÂ **identify road traffic signs**Â usingÂ **computer vision and convolutional neural networks (CNNs)**. The model was trained on theÂ **German Traffic Sign Recognition Benchmark (GTSRB)**Â dataset using aÂ **modified LeNet CNN architecture**.

This project is crucial forÂ **autonomous driving systems**Â andÂ **ADAS (Advanced Driver-Assistance Systems)**, where precise identification of road signs is essential for safety and navigation.

## Project highlights
- Designed and trained aÂ **deep learning model**Â forÂ **traffic sign recognition**, achievingÂ **95.1% accuracy**Â using a modifiedÂ **LeNet CNN architecture**.
- AddressedÂ **class imbalance**Â byÂ **augmenting underrepresented categories**, significantly improving classification consistency.
- ImplementedÂ **grayscaling & normalization**, reducing training time while maintaining model performance.
- **Optimized model generalization**Â by integratingÂ **dropout layers (70% in Conv1 & FC1)**, reducing overfitting byÂ **X%**.
- TunedÂ **Adam optimizer hyperparameters**Â (**learning rate = 0.001, batch size = 120**) to achieve peak performance.
- **Analyzed Softmax probabilities**Â to interpret model confidence, identifying edge cases like misclassification ofÂ **Stop & Yield signs**Â due toÂ **viewing angles**.
- DeployedÂ **data augmentation techniques**Â (rotation, brightness adjustment, scaling) toÂ **enhance model robustness**Â for real-world scenarios.

---

## ğŸ—Â **Project Architecture**

TheÂ **Traffic Sign Classifier**Â consists of the following key steps:

### 1ï¸âƒ£Â **Dataset & Preprocessing**

- **Problem:**Â The initial CNN model was overfitting due toÂ **uneven image distribution**Â across different classes. Some traffic signs had very few images, making it difficult for the model to generalize.
- **Solution:**
    - **Data Augmentation:**Â Added additional images to underrepresented classes, which significantly improved model accuracy.
    - **Grayscale Conversion:**Â Initially trained onÂ **normalized color images**, then switched toÂ **grayscale images**. While accuracy remained similar, grayscale imagesÂ **reduced training time**.

ğŸ“ŠÂ **Before and After Data Rebalancing**  


| Training data before rebalancing | Distribution after rebalancing |
|:---:|:---:|
| <img src="https://private-user-images.githubusercontent.com/13579623/265003217-432016d5-054f-42b3-bbf1-74efcaffd20c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzk4MjM3MDEsIm5iZiI6MTczOTgyMzQwMSwicGF0aCI6Ii8xMzU3OTYyMy8yNjUwMDMyMTctNDMyMDE2ZDUtMDU0Zi00MmIzLWJiZjEtNzRlZmNhZmZkMjBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAyMTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMjE3VDIwMTY0MVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE2OWRiZTM2Njg4NDY0NTY1NDIzYTg2NjJlMjIyMDk0OWRmYmIxY2FlODlmNjE1YWU3OTk2OGI3OTEzMzlmZjQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KMQjbCVfz4cC2yBB-p-PLOye9oziMAKrfMcSOqkrvcg" width="500"> | <img src="https://private-user-images.githubusercontent.com/13579623/265003402-be13f4f7-d8f5-4db5-a0de-defd116b0d75.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzk4MjM3MDEsIm5iZiI6MTczOTgyMzQwMSwicGF0aCI6Ii8xMzU3OTYyMy8yNjUwMDM0MDItYmUxM2Y0ZjctZDhmNS00ZGI1LWEwZGUtZGVmZDExNmIwZDc1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAyMTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMjE3VDIwMTY0MVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYyODBlZWY0ZDc3YzA2NzQ1NGJmOTk3NTkxMTVmYjhkYWU4MjkxOWE4NmI5ZmYzNjUyMzNkZTJmYzA1OTgzMmEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.nEF1LXdGzrhCSqMOK1XNUSSyLWLxGPYfKbwnXPviJ_o" width="400"> |



---

### 2ï¸âƒ£Â **Model Architecture**

The CNN used aÂ **modified LeNet architecture**Â with:

- **Two Convolutional Layers**
    - Conv1: 6 filters, 5x5 kernel, ReLU + Max Pooling
    - Conv2: 16 filters, 5x5 kernel, ReLU + Max Pooling
- **Three Fully Connected Layers**
    - FC1: 120 neurons, ReLU
    - FC2: 84 neurons, ReLU
    - Output: 43 classes (Softmax activation)

ğŸ“‰Â **Challenges & Solutions**:

- Initially, usingÂ **only max pooling**Â led toÂ **91% accuracy**, butÂ **top-5 probability analysis**Â showed misclassification due toÂ **overfitting**.
- **Solution:**Â IntroducedÂ **Dropout layers**Â inÂ **Conv1, FC1, and FC2**, which helpedÂ **reduce overfitting**Â and improved accuracy toÂ **95%**.
- The model requiredÂ **32x32x1 grayscale images**, which simplified computations.

ğŸ“ŠÂ **Visualization of Model Architecture**


<div class="mermaid">
graph TD
    A[Input: 32x32 Traffic Sign Image] -->|Grayscale + Normalize| B[Preprocessing]
    B -->|Data Augmentation| C{CNN Feature Extraction}
    
    C -->|Conv Layer 1: 5x5, ReLU| D[Max Pooling 1: 2x2]
    D -->|Conv Layer 2: 5x5, ReLU| E[Max Pooling 2: 2x2]
    
    E -->|Flatten Layer| F[Dense Layer: 120, ReLU]
    F -->|Dense Layer: 84, ReLU| G[Softmax Output 43 Classes]
    
    G --> H[Model Prediction]

</div>


---

### 3ï¸âƒ£Â **Model Training**

To optimize the training process,Â **several hyperparameters were tested**:

ğŸ”Â **Optimization Approach**:

- **Optimizer:**Â Adam (performed better than gradient descent)
- **Learning Rate:**Â 0.01 â†’ 0.001 (best at 0.001)
- **Batch Size:**Â Tested 100, 150, 200, 250 (best at 120)
- **Dropout Rate:**Â Experimented withÂ **50% to 70%**, foundÂ **70% best**Â forÂ `Conv1`Â andÂ `FC1`.

ğŸ› Â **Challenges & Fixes**: âœ…Â **Overfitting Issue:**Â Resolved usingÂ **dropout layers (70%)**  
âœ…Â **Slow Training Speed:**Â Switched toÂ **grayscale input**, reducing training time  
âœ…Â **Learning Instability:**Â Fine-tunedÂ **learning rate & batch size**


### Optimization
>[!info] Reduced overfitting via 70% dropout (Conv1, FC1) and fine-tuned Adam optimizer (learning rate=0.001, batch size=120). what this mean is this real

What this mean?
- **Overfitting**: Occurs when a model performs well on training data but fails to generalize to new data.
- **Dropout (70%)**: Dropout randomly â€œswitches offâ€ a portion of neurons during training, forcing the network to learn more robust, generalized features. While 70% is on the higher side (typical ranges are 30â€“50%), it can be effective in certain setups to combat heavy overfitting.
- **Conv1, FC1**: Applying dropout in the first convolutional layer and the first fully connected layer helps ensure both early and later-stage representations donâ€™t memorize training data too narrowly.
- **Fine-tuned Adam**: The Adam optimizer is widely used in deep learning. Setting aÂ **learning rate of 0.001**Â and aÂ **batch size of 120**Â is perfectly validâ€”these hyperparameters are often adjusted experimentally to balance convergence speed and stability.

---

### 4ï¸âƒ£Â **Performance Analysis**

**Final Model Performance**:

- **95% Accuracy**Â onÂ **test dataset**Â afterÂ **30 epochs**
- **Softmax Probability Analysis**Â for misclassified signs

**New Image Performance**:

- **Overall accuracy: 83%**
- **Stop sign misclassified**Â (likely due to angle distortion)  
    ğŸ› Â _Possible Fix_:Â **Perspective Transform**Â to standardize image angles

ğŸ“ŠÂ **Softmax Probability Insights**:

- **Yield, No Entry, and Caution Signs**Â predicted with high confidence
- **"Dangerous Curve to Right"**Â sign hadÂ **65% confidence**, butÂ **35% for "Slippery Road"**Â andÂ **5% for "Children Crossing"**.
    - _Reason:_Â All three signs areÂ **triangular**, causing confusion.
- **"60 km/h Speed Limit"**Â was predicted withÂ **80% confidence**, significantly higher than other probabilities.

ğŸ“ŠÂ **Softmax Prediction Visualization**  

[![image](https://private-user-images.githubusercontent.com/13579623/265002948-d1d7a756-59cd-429d-bd14-1ce2c1cd0b0d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzk4MjM3MDEsIm5iZiI6MTczOTgyMzQwMSwicGF0aCI6Ii8xMzU3OTYyMy8yNjUwMDI5NDgtZDFkN2E3NTYtNTljZC00MjlkLWJkMTQtMWNlMmMxY2QwYjBkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAyMTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMjE3VDIwMTY0MVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEyMzRmYTc2OTBmNjM2MzVjZjBhM2M3OWMzZThlYzQwZTc5ODRkY2QzYThkNWNlMmQyMDc0ODk4YjlmZTZhOTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VwrrYK0OP11N4UsQXD2mDO8cYGzL8aAjxJwXo2lzeu4)

---

## ğŸ†Â **Final Thoughts & Key Takeaways**

âœ”ï¸Â **Data Augmentation**Â helpedÂ **improve class balance**  
âœ”ï¸Â **Grayscale normalization**Â reducedÂ **training time**Â without accuracy loss  
âœ”ï¸Â **Dropout layers**Â helpedÂ **prevent overfitting**  
âœ”ï¸Â **Hyperparameter tuning**Â led toÂ **optimal performance**  
âœ”ï¸Â **Softmax analysis**Â revealedÂ **areas for improvement (angle correction, perspective transform)**

ğŸš€Â **Future Improvements**:

- ImplementÂ **perspective transformation**Â for better real-world performance
- Test model onÂ **real-world dashcam traffic images**
- Deploy model in anÂ **embedded ADAS system for real-time traffic sign recognition**