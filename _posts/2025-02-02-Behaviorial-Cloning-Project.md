---
layout: mermaid-post
tags:
  - ai
  - project
---


This is project I did on **Behavioral Cloning for Autonomous Driving Using Convolutional Neural Network (CNN)**
if you are interested in code its here [Project github repo](https://github.com/oalahurikar/Self-Driving/tree/master/Term1/3.%20Behaviorial%20Cloning).

## ğŸ“Â **Project Overview**

Behavioral cloning is an approach in deep learning where a neural network learns to mimic human behaviorâ€”in this case, driving a car based on visual inputs. This project leveragesÂ LeNet **Convolutional Neural Networks (CNNs)** architectureÂ to predict steering angles using images captured from a front-facing camera of a self-driving car.

ğŸ“ŒÂ **Goal:**Â Train aÂ **CNN**Â to predict steering angles from road images.  
ğŸ“ŒÂ **Tech Stack:**Â `Keras`,Â `TensorFlow`,Â `Python`,Â `OpenCV`  
ğŸ“ŒÂ **Data:**Â ~**4825 images**Â from a simulated environment.

## ğŸ“¸Â  Training data
I used images fromÂ **three cameras**Â (center, left, right) to teach the car how to drive.  
To help it learn how to recover when off-track, I added aÂ **steering correction of Â±0.4**Â for left and right images.  
I recorded data while:
- Driving normally in the center of the lane (2 laps)
- Letting the car drift and recover before crashing
- Driving the track in reverse (1 lap)

In total, I collected aboutÂ **4,825 images**Â to train the model.

|Center view|Left view|Right view|
|---|---|---|
|[![alt_text-1](https://github.com/oalahurikar/Behaviorial-Cloning/raw/master/Images%20and%20Graphs/Camera%20Center.jpg)](https://github.com/oalahurikar/Behaviorial-Cloning/blob/master/Images%20and%20Graphs/Camera%20Center.jpg)|[![alt_text-2](https://github.com/oalahurikar/Behaviorial-Cloning/raw/master/Images%20and%20Graphs/Camera%20Left.jpg)](https://github.com/oalahurikar/Behaviorial-Cloning/blob/master/Images%20and%20Graphs/Camera%20Left.jpg)|[![alt_text-3](https://github.com/oalahurikar/Behaviorial-Cloning/raw/master/Images%20and%20Graphs/Camera%20Right.jpg)](https://github.com/oalahurikar/Behaviorial-Cloning/blob/master/Images%20and%20Graphs/Camera%20Right.jpg)|

## ğŸ—Â **Project Architecture**

Project's workflow:

<div class="mermaid">
graph TD
  A[Data Collection] --> B[Preprocessing]
  B --> C[Data Augmentation]
  C --> D[CNN Model]
  D --> E[Training with Adam Optimizer]
  E --> F[Evaluation & Validation]
  F --> G[Autonomous Driving Test]
  G -->|Success| H[Model Deployment]
  G -->|Failure| E[Re-train Model]
</div>


## ğŸ“ŠÂ **Key Components & Features**

| ğŸ”¹Â **Component**               | ğŸ”Â **Details**                                              |
| ------------------------------ | ----------------------------------------------------------- |
| ğŸ“¸Â **Data Collection**         | 3 Camera views (Left, Center, Right) to improve robustness. |
| âœ‚Â **Preprocessing**            | Cropping sky & hood, normalizing pixel values.              |
| ğŸ­Â **Data Augmentation**       | Flipping, brightness adjustment, adding shadows.            |
| ğŸ—Â **Model Architecture**      | **CNN**Â â†’ 6 Conv layers + 4 Fully Connected layers.         |
| ğŸ› Â **Training Strategy**       | **Optimizer:**Â AdamÂ **Loss Function:**Â MSE                  |
| ğŸ”„Â **Overfitting Reduction**   | Dropout layers, pooling, increased dataset.                 |
| ğŸÂ **Final Model Performance** | Successfully completed lap without drifting!                |

## ğŸ—Â **LeNet CNN Model Architecture**

<div class="mermaid">
graph TD
  A[Input Image 160x320x3] --> B[Lambda Layer - Normalization]
  B --> C[Cropping Layer - Remove sky & hood]
  C --> D[Conv Layer 5x5 - 24 filters, RELU]
  D --> E[Conv Layer 5x5 - 36 filters, RELU]
  E --> F[Conv Layer 5x5 - 48 filters, RELU]
  F --> G[Conv Layer 3x3 - 64 filters, RELU]
  G --> H[Conv Layer 3x3 - 64 filters, RELU]
  H --> I[Flatten]
  I --> J[Fully Connected - 100 neurons, RELU]
  J --> K[Fully Connected - 50 neurons, RELU]
  K --> L[Fully Connected - 10 neurons, RELU]
  L --> M[Output - Steering Angle]
</div>

---
## ğŸ“ˆÂ **Model Training & Performance**

|**ğŸ”¹ Training Set Size**|**âš  MSE Loss**|**ğŸš— Performance**|
|---|---|---|
|**2048 images**|âŒ High|Drifts off track|
|**4825 images**|âœ… Lower|Completes lap ğŸš€|

---

## ğŸÂ **Final Results**

âœ… Model successfully drives autonomously without manual intervention.  
âœ… Improved performance usingÂ **data augmentation + dropout layers**.  
âœ…Â **MSE Loss reduced significantly**Â with more training data.

---

## **ğŸš€ Key Observations**

**1ï¸âƒ£ Small Dataset (2048 samples)**
â€¢ ğŸ“‰ **Training Loss** drops significantly but quickly â†’ **Overfitting** risk! ğŸš¨
â€¢ ğŸ“ˆ **Validation Loss** remains flat or slightly increases â†’ **Poor generalization**

**2ï¸âƒ£ Large Dataset (4825 samples)**
â€¢ ğŸ“‰ **Training Loss** decreases **steadily**
â€¢ ğŸ“‰ **Validation Loss** also decreases â†’ **Better generalization** ğŸ†

â€¢ **Training & Validation Loss converge** more smoothly â†’ **Less overfitting**

| MSE with small data | MSE with Large data (Final solution) |
|:---:|:---:|
| ![MSE with small data](https://github.com/oalahurikar/Behaviorial-Cloning/raw/master/MSE%20Error1.png) | ![MSE with large data](https://github.com/oalahurikar/Behaviorial-Cloning/raw/master/MSE%20Error2.png) |

### **ğŸ“Œ What these results mean** 
âœ… **Overfitting Reduction** â€“ Increasing data **reduced the training-validation gap**
âœ… **Better Generalization** â€“ Validation loss **decreased**, meaning it performs well on unseen data
âœ… **Final Model Stability** â€“ Training and validation loss **align**, meaning the model is **learning correctly**
âœ… **Performance Boost** â€“ Initial validation loss ~0.06, final validation loss ~0.045 â†’ **~25% improvement!** ğŸ“‰

---

## ğŸ”®Â **Next Steps**

ğŸ”¹ Test onÂ **real-world driving datasets**Â ğŸš—  
ğŸ”¹ Optimize withÂ **Reinforcement Learning**Â ğŸ¤–  
ğŸ”¹ Deploy onÂ **Embedded Hardware (Jetson Nano, Raspberry Pi)**